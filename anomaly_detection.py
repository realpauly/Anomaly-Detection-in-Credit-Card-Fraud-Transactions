# -*- coding: utf-8 -*-
"""Anomaly_Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MhNPHAw1SWbhsfUjjMBWgPB1Oo4Nz4xd
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import IsolationForest
from sklearn.neighbors import LocalOutlierFactor
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (precision_score, recall_score,
                              f1_score, roc_auc_score, classification_report)

# Step 1: Load the dataset
data = pd.read_csv('creditcard.csv')

# Step 2: Preprocessing
# Check for missing values
#print("Missing values per column:\n", data.isnull().sum())

# Normalize the "Amount" feature
scaler = StandardScaler()
data['Amount'] = scaler.fit_transform(data[['Amount']])

# Drop the "Time" column (if present, as it might not be useful for detection)
if 'Time' in data.columns:
    data = data.drop(columns=['Time'])

# Step 3: Explore the dataset
print("\nClass distribution:")
print(data['Class'].value_counts())
print("\nPercentage of Fraudulent Transactions:")
fraud_percentage = data['Class'].value_counts(normalize=True)[1] * 100
print(f"{fraud_percentage:.2f}%")

# Visualization: Class Distribution
plt.figure(figsize=(8, 6))
sns.countplot(x='Class', data=data, palette='viridis', hue='Class',
dodge=False, legend=False)
plt.title('Distribution of Normal vs Fraudulent Transactions')
plt.xlabel('Class (0 = Normal, 1 = Fraud)')
plt.ylabel('Count')
plt.show()

# Visualization: Amount Distribution for Fraud vs Normal Transactions
plt.figure(figsize=(10, 6))
sns.countplot(x='Class', data=data, palette='viridis', hue='Class',
dodge=False, legend=False)
plt.title('Transaction Amount Distribution by Class')
plt.xlabel('Class (0 = Normal, 1 = Fraud)')
plt.ylabel('Normalized Amount')
plt.yscale('log')  # Scale to log to visualize outliers better
plt.show()

# Visualization: Correlation Heatmap
plt.figure(figsize=(12, 10))
corr = data.corr()
sns.heatmap(corr, annot=False, cmap='coolwarm', cbar=True)
plt.title('Correlation Heatmap')
plt.show()

# Separate features and labels
X = data.drop(columns=['Class'])
y = data['Class']

# Step 4: Implement Anomaly Detection Techniques
# Define contamination based on fraud percentage
contamination_rate = fraud_percentage / 100

# Isolation Forest
iso_forest = IsolationForest(contamination=contamination_rate,
random_state=42)
y_pred_iso = iso_forest.fit_predict(X)
y_pred_iso = np.where(y_pred_iso == 1, 0, 1)
# Local Outlier Factor
lof = LocalOutlierFactor(n_neighbors=20, contamination=contamination_rate)
y_pred_lof = lof.fit_predict(X)
y_pred_lof = np.where(y_pred_lof == 1, 0, 1)

# Step 5: Evaluate Performance
# Helper function for evaluation
def evaluate_model(y_true, y_pred, model_name):
    print(f"\nPerformance Metrics for {model_name}:")
    print("Precision:", precision_score(y_true, y_pred))
    print("Recall:", recall_score(y_true, y_pred))
    print("F1-Score:", f1_score(y_true, y_pred))
    print("ROC-AUC:", roc_auc_score(y_true, y_pred))
    print("\nClassification Report:\n", classification_report(y_true, y_pred))

# Evaluate Isolation Forest
evaluate_model(y, y_pred_iso, "Isolation Forest")

# Evaluate Local Outlier Factor
evaluate_model(y, y_pred_lof, "Local Outlier Factor")

# Visualization: ROC Curve
from sklearn.metrics import roc_curve, auc

# Function to plot ROC Curve
def plot_roc_curve(y_true, y_pred, model_name):
    fpr, tpr, _ = roc_curve(y_true, y_pred)
    roc_auc = auc(fpr, tpr)

    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='darkorange', lw=2,
    label=f'{model_name} (AUC = {roc_auc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.title(f'ROC Curve - {model_name}')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.legend(loc="lower right")
    plt.show()

# Plot ROC Curve for both models
plot_roc_curve(y, y_pred_iso, "Isolation Forest")
plot_roc_curve(y, y_pred_lof, "Local Outlier Factor")